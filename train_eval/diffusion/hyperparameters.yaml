main: 
  random_state: 10
  batch_size: 1
  epochs: 200
  buffer_size: 50 # Size of the buffer to store generated images
  caption_forward: "person to anime character"
  caption_reverse: "anime character to person"

data:
  data_part: 0.999 # Proportions to split data for train and evaluation
  sub_part_data: 1 # Part of picked data to use for training (useful for project tests, for real training process set == 1)
  size: [256, 256]
  mean: [0.5, 0.5, 0.5]
  std: [0.5, 0.5, 0.5]

distributed:
  world_size: 2  # Number of GPU/CPU
  # Initialization the default distributed process group
  backend: 'nccl' # 'nccl' -- for GPU, 'gloo' for CPU
  port: '12345'
  address: 'localhost'

optimizers:
  gen:
    lr: 5e-6
    betas: [0.9, 0.999]
    weight_decay: 0.01
  discA:
    lr: 5e-6
    betas: [0.9, 0.999]
    weight_decay: 0.01
  discB:
    lr: 5e-6
    betas: [0.9, 0.999]
    weight_decay: 0.01

generator:
  unet_lora_rank: 128
  vae_lora_rank: 4
  gamma: 1

discriminator:
  cv_type: 'clip'
  loss_type: 'multilevel_sigmoid'

loss:
  adversarial:
    adv_alpha: 0.5

  cycle:
    ltype: 'L1'
    lambda_A: 1.0
    lambda_B: 1.0
    lambda_lpips: 10.0

  identity:
    ltype: 'L1'
    lambda_idn: 1
    lambda_lpips: 1
